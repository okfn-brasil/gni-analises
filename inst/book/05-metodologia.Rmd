# Metodologia {#metodologia}

Para selecionar os diários e os conteúdos relevantes para as pessoas usuárias do Diário do Clima, nós utilizamos prioritariamente técnicas de processamento de linguagem natural (NLP, em inglês). Estas técnicas são compostas de regras lógicas ou modelos estatísticos que permitem que se estruture e interprete informação textual de forma automatizada. A ordem das tarefas analíticas foi:

1. Pré-processamento do conteúdo dos diários oficiais;
2. Desenvolvimento de mecanismos de busca no conteúdo processado;
3. Definição dos termos de busca a serem utilizados para identificar conteúdo processado;
4. Avaliação quantitativa e qualitativa dos resultados de busca.

## Pré-processamento de um Diário Municipal
(LCOELHO desenvolver)

- Escolher um diário oficial para colar a foto aqui;
- Colar uma foto mostrando o texto extraído de forma bruta;
- Explicar expressões regulares;
- Eliminação de caracteres duplicados, marcações de parágrafos;
- Mostrar diário limpo.

## Mecanismos de Busca
Nós utilizamos o sistema de dados Elasticsearch, da empresa Elastic, que é uma das plataformas mais populares de armazenamento de dados textuais e recuperação de conteúdo, uma vez que é um sistema seguro, eficiente e de baixo custo. A plataforma contém ferramentas de busca textual em que a pessoa usuária define termos de busca (e.g. "cão chupando manga") e forma de busca (e.g. busca que contenham todos os termos entre aspas). Para este projeto, utilizou-se os seis tipos de busca a seguir:

### Intervalar
Busca que define termos que iniciais e finais de um intervalo de conteúdo dentro de um Diário Oficial para que o documento seja retornado à pessoa usuária. A pessoa pode também definir o tamanho do intervalo de modo que os documentos retornados contenham termos iniciais próximos ou distantes dos termos finais.

**Como funciona:**  Se o interesse for em encontrar diários que contenham os termos "preservação" e "ambiental", a busca intervalar permite que definamos uma distância máxima entre estes dois termos de modo que seja mais fácil retornar o conteúdo desejado (e.g. "**preservação** de parque nacional de acordo com boas práticas de política **ambiental** brasileira.", distância de 10 termos entre as palavras buscadas). Contudo, se estes termos estiverem muito distantes, podemos encontrar um contexto em que "preservação" não diz respeito à temática ambiental e que "ambiental" se refere a outro contexto que não de preservação (e.g. "preservação de direitos trabalhistas" no início do diário e "licenciamento ambiental" no final)

### Querystring
Busca em que se utiliza uma sintaxe própria do Elasticsearch para analisar e dividir o conjunto de caracteres de consulta fornecido com base em operadores booleanos como AND ("e"), NOT ("não") e OR ("ou"). Cada termos é primeiro analisado independente e depois analisado em conjunto segundo os operadores acima. 

**Como funciona:** A busca analisa as palavras na frase que se deseja encontrar no diário de maneira independente. Todas as palavras são convertidas em _tokens_ (após passar pelo processo de _tokenização_, as frases são separadas em pedaços chamados de tokens - não é possível chamá-los de palavras pois um token pode ser um valor monetário, como R$ 20,00) caso a condição seja verdadeira o diário será retornado. Tomando o exemplo "preservação AND ambiental" a busca será válida caso o diário contenha os dois termos, nesse caso o diário seria retornado na pesquisa.
 
### Booleana
Uma consulta que corresponde a documentos correspondentes a combinações booleanas de outras consultas. A consulta é construída usando uma ou mais cláusulas booleanas, cada cláusula com uma ocorrência digitada. Os tipos de ocorrência são:
    _must_    : O termo deve, obrigatoriamente, aparecer no documento.
    _filter_  : O termo deve aparecer nos documentos correspondentes.
    _should_  : O termo deve aparecer no documento.
    _must_not_: O termo não deve, obrigatoriamente, aparecer no documento.

**Como funciona:** A estrutura requer o conhecimento das palavras a serem procuradas no diário e as condições para que o retorno desse determinado diário seja válido. Portanto, continuando no mesmo exemplo, deveríamos encontrar um _must_: {preservação}, {ambiental} podendo adicionar uma camada de _must_not_: {direitos trabalhistas}, ou ainda _filter_: {política nacional do meio ambiente}, caso o interesse fosse descobrir os municípios que estão executando ações de preservação voltadas às diretrizes da PNMA.

### Boosting
Retorna documentos que correspondem a uma consulta positiva enquanto reduz a pontuação de relevância dos documentos que correspondem a uma consulta negativa. Essa consulta permite rebaixar certos documentos sem excluí-los dos resultados da pesquisa.

**Como funciona:** Partindo da premissa que se uma palavra está contida no título do diário é provável que este tipo de conteúdo seja o tema central do documento, neste caso é de interesse que o boosting esteja relacionado com a presença das palavras: {preservação, ambiental} no título. Dessa forma, para aqueles diários que contenham essas palavras no título será dada uma nota de relevância maior do que aqueles que só contenham essas palavras no corpo do texto.

### Fuzzy
Retorna documentos que contém termos semelhantes ao termo de pesquisa medido por uma distância de edição. Uma distância de edição é o número de alterações de um caractere necessárias para transformar um termo em outro. Essas mudanças podem incluir:

**Como funciona**: A própria busca fuzzy a partir de uma distância informada consegue achar similaridades nas palavras pela criação de um conjunto de variação a partir dos artifícios exemplificados abaixo:
- Mudando um caractere que muda a palavra (gato -> galo)
- Removendo caracteres (acreditar -> creditar)
- Inserindo caracteres (calor -> calorímetro)
- Transpondo caracteres adjacentes (papo -> popa)

É possível inserir apenas uma parte da palavra, por exemplo: {preser} e {ambi}. Dessa forma, a pesquisa mesmo assim irá retornar documentos que contenham as palavras preservação mas também pode retornar palavras como "preservado", "reservado", dentre outros. É importante salientar que todas esssas modificações nas palavras podem ser controladas na busca, a partir da distância e também autorizando os atributos que serão utilizados para separarem as palavras nesses conjuntos.

### Expressões regulares (Regexp)

Retorna documentos que contém termos que correspondem a uma expressão regular. Uma expressão regular é uma maneira de combinar padrões em dados usando caracteres de espaço reservado, chamados de operadores. 

**Como funciona**: É possível encontrar estruturas de frases completas utilizando os operadores das expressões regulares. A busca pode retornar frases como "Texto preservação ambiental texto no município texto {ano}". Neste tipo de pesquisa o interesse é buscar diários que contenham o ano de criação, implementação ou outro tipo de informação relacionado ao período das ações de preservação ambiental implementadas no município. Portanto, não é necessário saber exatamente o que está presente no texto, mas apenas com operadores de expressões regulares é possível construir uma frase em que o produto seja algo de interesse para a pesquisa.

_**(pergunta)As consultas podem ser feitas em conjunto? Por exemplo, integrar bool com boosting?**_

## Anotação e Controle de Qualidade
   
O processo de criação das palavras de busca é acompanhado de um longo trabalho envolvendo uma curadoria de jornalistas especializados. Foram selecionados voluntariamente sete jornalistas para compor a equipe de curadoria e avaliar os documentos coletados através dos mecanismos de busca e avaliar qualitativamente os resultados.
   
Para esta fase do projeto os curadores irão avaliar cerca de 776 termos de busca. Na primeira etapa serão gerados 488 termos acompanhados de excertos dos Diários Oficiais coletados, denominados de _highlights_. A partir dos resultados da primeira etapa será necessário mais duas avaliações de 144 termos para concluir o processo.
   
A definição das stopwords e stoplists é crucial para a determinação do escopo do projeto, ou seja, o que será encontrado na platadorma Diário do Clima.

## Avaliação de precisão

A avaliação de precisão é realizada concomitantemente com as criações de stopwords e stoplists, já que estas duas etapas são interdependentes. 

   Na avaliação feita pelos curadores, existem dois parâmetros que podem ser explorados, um deles diz respeito ao escopo do documento se adequado (positivo) ou não (negativo) e o outro é com relação aos comentários dos curadores no documento, sendo este indicador opcional. Na distribuição dos termos, há ainda mais um parâmetro que também pode ser adicionado, que é a qualidade dos documentos baseados nas palavras coletadas via ElasticSearch, assim os primeiros documentos possuem uma qualidade teórica maior do que aqueles que vem por último para cada termo de busca.
   
   Todos os documentos são avaliados, portanto é possível tirar conclusões muito importantes para o desenvolvimento das buscas nos Diários Oficiais dos municípios. As avaliações serão divididas em análises quantitativa e qualitativa.

 * **Quantitativa**
 
 A análise quantitativa se baseará em duas principais relações: Índices positivos e negativos de busca, relação entre qualidade do documento ElasticSearch versus qualidade pela Curadoria.
 
 O primeiro inferirá sobre a distribuição das avaliaçõe negativas e positivas dos documentos, podendo então saber se os documentos coletados estão coerentes com o objetivo da plataforma. O segundo ajudará a melhorar a qualidade traçando uma relação entre os índices de qualidade pelo ElasticSearch e a quantidade de índices positivos ou negativos daquela busca.

Existem alguns indicadores importantes que servem para avaliar os resultados da busca. Isso é realizado com o auxílio da equipe de curadores, em que proporcionarão sobre a qualidade do resultado retornado, classificando-o em resultado positivo ou negativo. Nesse caso é possível avaliar: 
**1) Acurácia**
Diários retornados positivos dividido pelo total dos resultados.

**2) Recall**
Retorna todos aqueles casos relevantes, sendo:
Verdadeiros positivos dividido pela soma dos verdadeiros positivos e falsos negativos

**3) Precisão**

Verdadeiros positivos dividido pela soma dos verdadeiros positivos e falsos positivos

Como o indicador **2** e **3** possuem relações complementares então foi desenvolvido outro indicador que avalia o composto total.

**4) F1-Score**
F1 = 2* (precisão*recall)/(precisão+recall)

TF-IDF = term frequency*inverse document frequency

  * **Qualitativa**
  
 A análise qualitativa será realizada para observar o conteúdo dos highlights e comentários realizados. Assim, será possível avaliar se os highlights selecionados são adequados ao escopo do documento que ele faz parte
   
   Após a coleta dos documentos e definição dos termos de busca será feita uma nova rodada de coleta de documentos para refinar os processos de busca. Essa etapa é necessária para deixar a plataforma mais eficaz e amigável, bem como melhorar o processamento dos documentos. 
   
   Esse processo vai de encontro com o que foi elencado na seção de Política ambiental no Brasil, onde puderam ser explorados os principais marcos da política ambiental brasileira bem como a avaliação dos documentos pelos curadores.Dessa forma, a plataforma será um grande êxito para os jornalistas e comunicadores que acompanham nóticias sobre clima e meio ambiente no Brasil. 

## Termos de Interesse
(LCOELHO desenvolver)

- Quais os termos de busca da planilha?
- Quais os termos comuns das políticas da seção 04 que podem ser utilizados aqui?

## Anotação e Controle de Qualidade

Para verificar se os resultados da busca automática foram positivos, nós utilizamos uma equipe de pessoas anotadoras, especialistas em temática ambiental, para verificar os conteúdos retornados. Estas pessoas compõem a equipe de curadoria do Diário do Clima.

Na avaliação feita pelas pessoas curadoras, existem dois parâmetros que podem ser explorados; o primeiro deles indica se o documento possui o escopo adequado (positivo) ou não (negativo); o segundo permite comentários dos curadores com relação aos termos de busca, em que essas pessoas dividem com a equipe da OKBR problemas ou benefícios daquele tipo de busca. Finalmente, contamos com um terceiro parâmetro de qualidade da busca, qual seja, a nota de relevância dos documentos retornados, que é gerada automaticamente pela Elasticsearch. Em teoria, os primeiros documentos retornados, com notas mais altas, possuem qualidade maior do que aqueles que vêm por último.

Todos os documentos retornados são avaliados, mesmos aqueles que tenham baixa qualidade. Este mecanismo permite que possamos ajustar o mecanismo de busca e as palavras-chaves dinamicamente, conforme a equipe de curadora desenvolve seu trabalho.

**Controle de Qualidade Quantitativo.** A análise quantitativa sobre qualidade da busca se baseia em dois indicadores principais: índices positivos e negativos de busca e relação entre qualidade do documento Elasticsearch versus qualidade pela Curadoria.

**Controle de Qualidade Qualitativo.** A análise qualitativa baseou-se em conteúdo dos _highlights_ e comentários realizados.

**Refinamento.** Após a coleta dos documentos e definição dos termos de busca, fizemos reiteramos o processo descrito acima para refinar os processos de busca. Essa etapa é necessária para deixar a plataforma mais eficaz e amigável, bem como melhorar o processamento dos documentos.


-------------------------------

(LCOELHO material de antes, para usar em cima se quiser ou apagar se não quiser)

**1** Pré-processamento

Processo realizado previamente pelo Querido Diário, consiste em mapear os Diários Oficiais Municipais, obter raspadores para cada um destes e ser capaz de converter os documentos em texto puro e metadados, armazenando através do Elasticsearch.
**2** Mecanismos de Busca

A recuperação de informações (RI) pode ser feita através de um sistema que funciona a partir de diferentes mecanismos, sejam análise textual, filtragem de informação por meio da extração de stopwords, técnicas de redução de palavras a seus radicais, técnicas de indexação, arquivo invertido, modelos matemáticos e estatísticos para a representação de documentos, de consultas e a definição de coeficientes de similaridades, estruturas de categorização e de expansão de consultas por meio da utilização de Tesauro [Souza, 2005](https://repositorio.ufmg.br/bitstream/1843/RRSA-6GGGUF/1/doutorado___renato_rocha_souza.pdf).

**3** Stopwords e Stoplists

 O processo de criação das palavras de busca é acompanhado de um longo trabalho envolvendo uma curadoria de jornalistas especializados. Foram selecionados voluntariamente sete jornalistas para compor a equipe de curadoria e avaliar os documentos coletados através dos mecanismos de busca e avaliar qualitativamente os resultados.

 Para esta fase do projeto os curadores irão avaliar cerca de 776 termos de busca. Na primeira etapa serão gerados 488 termos acompanhados de excertos dos Diários Oficiais coletados, denominados de _highlights_. A partir dos resultados da primeira etapa será necessário mais duas avaliações de 144 termos para concluir o processo.

 A definição das stopwords e stoplists é crucial para a determinação do escopo do projeto, ou seja, o que será encontrado na platadorma Diário do Clima.
**4** Avaliação de precisão

