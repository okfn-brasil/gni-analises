# Metodologia {#metodologia}

Para selecionar os diários e os conteúdos relevantes para as pessoas usuárias do Diário do Clima, nós utilizamos prioritariamente técnicas de processamento de linguagem natural (NLP, em inglês). Estas técnicas são compostas de regras lógicas ou modelos estatísticos que permitem que se estruture e interprete informação textual de forma automatizada. A ordem das tarefas analíticas foi:

1. Pré-processamento do conteúdo dos diários oficiais;
2. Desenvolvimento de mecanismos de busca no conteúdo processado;
3. Definição dos termos de busca a serem utilizados para identificar conteúdo processado;
4. Avaliação quantitativa e qualitativa dos resultados de busca.


## Pré-processamento de um Diário Municipal

(LCOELHO desenvolver)
Processo realizado previamente pelo Querido Diário, consiste em mapear os Diários Oficiais Municipais, obter raspadores para cada um destes e ser capaz de converter os documentos em texto puro e metadados, armazenando através do ElasticSearch.

- Escolher um diário oficial para colar a foto aqui;
- Colar uma foto mostrando o texto extraído de forma bruta;
- Explicar expressões regulares;
- Eliminação de caracteres duplicados, marcações de parágrafos;
- Mostrar diário limpo.

## Mecanismos de busca

Nós utilizamos o sistema de dados Elasticsearch, da empresa Elastic, que é uma das plataformas mais populares de armazenamento de dados textuais e recuperação de conteúdo, uma vez que é um sistema seguro, eficiente e de baixo custo. A plataforma contém ferramentas de busca textual em que a pessoa usuária define termos de busca (e.g. "cão chupando manga") e forma de busca (e.g. busca que contenham todos os termos entre aspas). Para este projeto, utilizou-se os seis tipos de busca a seguir:

### Intervalar

  Retorna documentos com base na ordem e proximidade dos termos correspondentes. A consulta de intervalos usa regras de correspondência, construídas a partir de um pequeno conjunto de definições. Essas regras são então aplicadas aos termos de um campo especificado. As definições produzem sequências de intervalos mínimos que abrangem termos em um corpo de texto. 
    **Exemplo**:
   
### Querystring

Aqui é utilizada uma sintaxe para analisar e dividir o conjunto de caracteres de consulta fornecida com base em operadores booleanos como AND, NOT e OR. Cada texto é analisado independente e após isso são retornados os documentos. Também é possível utilizar a consulta query_string para criar uma pesquisa complexa que inclui caracteres versáteis, pesquisas em vários campos e muito mais. A desvantagem desse método é que se a sintaxe for inválida um erro será retornado na busca.
   **Exemplo**:
    
### Booleana

Uma consulta que corresponde a documentos correspondentes a combinações booleanas de outras consultas. A consulta é construída usando uma ou mais cláusulas booleanas, cada cláusula com uma ocorrência digitada. Os tipos de ocorrência são:
      _must_    : O termo deve, obrigatoriamente, aparecer no documento.
      _filter_  : O termo deve aparecer nos documentos correspondentes.
      _should_  : O termo deve aparecer no documento.
      _must_not_: O termo não deve, obrigatoriamente, aparecer no documento.
      
   **Exemplo**:
   
 
### Boosting

Retorna documentos que correspondem a uma consulta positiva enquanto reduz a pontuação de relevância dos documentos que correspondem a uma consulta negativa. Essa consulta permite rebaixar certos documentos sem excluí-los dos resultados da pesquisa.

   **Exemplo**:
      
### Fuzzy

Retorna documentos que contém termos semelhantes ao termo de pesquisa medido por uma distância de edição. Uma distância de edição é o número de alterações de um caractere necessárias para transformar um termo em outro. Essas mudanças podem incluir:

- Mudando um caracter que muda a palavra (gato -> galo)
- Removendo caracteres (acreditar -> creditar)
- Inserindo caracteres (calor -> calorímetro)
- Transpondo caracteres adjacentes (papo -> popa)
     
   Para encontrar termos semelhantes, a consulta do tipo fuzzy cria um conjunto de todas as variações ou expansões possíveis do termo de pesquisa dentro de uma distância de edição especificada. A consulta retorna correspondências exatas para cada expansão.
   
   **Exemplo**:
  
### Expressões regulares (Regexp)

Retorna documentos que contém termos que correspondem a uma expressão regular. Uma expressão regular é uma maneira de combinar padrões em dados usando caracteres de espaço reservado, chamados de operadores. Para obter uma lista de operadores suportados pela consulta regexp.

   **Exemplo**:

## Anotação e Controle de Qualidade
   
O processo de criação das palavras de busca é acompanhado de um longo trabalho envolvendo uma curadoria de jornalistas especializados. Foram selecionados voluntariamente sete jornalistas para compor a equipe de curadoria e avaliar os documentos coletados através dos mecanismos de busca e avaliar qualitativamente os resultados. 
   
Para esta fase do projeto os curadores irão avaliar cerca de 776 termos de busca. Na primeira etapa serão gerados 488 termos acompanhados de excertos dos Diários Oficiais coletados, denominados de _highlights_. A partir dos resultados da primeira etapa será necessário mais duas avaliações de 144 termos para concluir o processo.
   
A definição das stopwords e stoplists é crucial para a determinação do escopo do projeto, ou seja, o que será encontrado na platadorma Diário do Clima. 
   
## Avaliação de precisão

A avaliação de precisão é realizada concomitantemente com as criações de stopwords e stoplists, já que estas duas etapas são interdependentes. 

   Na avaliação feita pelos curadores, existem dois parâmetros que podem ser explorados, um deles diz respeito se o documento possui o escopo adequado (positivo) ou não (negativo) e o outro é com relação aos comentários dos curadores no documento, sendo este indicador opcional. Na distribuição dos termos, há ainda mais um parâmetro que também pode ser adicionado, que é a qualidade dos documentos baseados nas palavras coletadas via ElasticSearch, assim os primeiros documentos possuem uma qualidade teórica maior do que aqueles que vem por último para cada termo de busca.
   
   Todos os documentos são avaliados, portanto é possível tirar conclusões muito importantes para o desenvolvimento das buscas nos Diários Oficiais dos municípios. As avaliações serão divididas em análises quantitativa e qualitativa.

 * **Quantitativa**
 
 A análise quantitativa se baseará em duas principais relações: Índices positivos e negativos de busca, relação entre qualidade do documento ElasticSearch versus qualidade pela Curadoria.
 
 O primeiro inferirá sobre a distribuição das avaliaçõe negativas e positivas dos documentos, podendo então saber se os documentos coletados estão coerentes com o objetivo da plataforma. O segundo ajudará a melhorar a qualidade traçando uma relação entre os índices de qualidade pelo ElasticSearch e a quantidade de índices positivos ou negativos daquela busca.

  * **Qualitativa**
  
 A análise qualitativa será realizada para observar o conteúdo dos highlights e comentários realizados. Assim, será possível avaliar se os highlights selecionados são adequados ao escopo do documento que ele faz parte
   
   Após a coleta dos documentos e definição dos termos de busca será feita uma nova rodada de coleta de documentos para refinar os processos de busca. Essa etapa é necessária para deixar a plataforma mais eficaz e amigável, bem como melhorar o processamento dos documentos. 
   
   Esse processo vai de encontro com o que foi elencado na seção de Política ambiental no Brasil, onde puderam ser explorados os principais marcos da política ambiental brasileira bem como a avaliação dos documentos pelos curadores.Dessa forma, a plataforma será um grande êxito para os jornalistas e comunicadores que acompanham nóticias sobre clima e meio ambiente no Brasil. 


## Um Diário Municipal

## Mecanismos de Busca

## Termos de Interesse

