# Metodologia {#metodologia}

A metodologia de trabalho foi sub-dividida em cinco etapas, sendo: Pré-processamento, mecanismos de busca, stopwords e stoplists, refinamento e avaliação de precião. Cada uma delas será explorada nessa seção.


>> **1** Pré-processamento

Processo realizado previamente pelo Querido Diário, consiste em mapear os Diários Oficiais Municipais, obter raspadores para cada um destes e ser capaz de converter os documentos em texto puro e metadados, armazenando através do ElasticSearch. 

>> **2** Mecanismos de Busca

A recuperação de informações (RI) pode ser feita através de um sistema que funciona a partir de diferentes mecanismos, sejam análise textual, filtragem de informação por meio da extração de stopwords, técnicas de redução de palavras a seus radicais, técnicas de indexação, arquivo invertido, modelos matemáticos e estatísticos para a representação de documentos, de consultas e a definição de coeficientes de similaridades, estruturas de categorização e de expansão de consultas por meio da utilização de Tesauro [Souza, 2005](https://repositorio.ufmg.br/bitstream/1843/RRSA-6GGGUF/1/doutorado___renato_rocha_souza.pdf).

Para este projeto foram utilizados seis tipos de busca, a saber:

  *_Intervalar_*
  Retorna documentos com base na ordem e proximidade dos termos correspondentes. A consulta de intervalos usa regras de correspondência, construídas a partir de um pequeno conjunto de definições. Essas regras são então aplicadas aos termos de um campo especificado. As definições produzem sequências de intervalos mínimos que abrangem termos em um corpo de texto. 
    *Exemplo*:
   
  *_Querystring_*
  Aqui é utilizada uma sintaxe para analisar e dividir o conjunto de caracteres de consulta fornecida com base em operadores booleanos como AND, NOT e OR. Cada texto é analisado independente e após isso são retornados os documentos. Também é possível utilizar a consulta query_string para criar uma pesquisa complexa que inclui caracteres versáteis, pesquisas em vários campos e muito mais. A desvantagem desse método é que se a sintaxe for inválida um erro será retornado na busca.
    *Exemplo*:
    
  *_Booleana_*
  Uma consulta que corresponde a documentos correspondentes a combinações booleanas de outras consultas. A consulta é construída usando uma ou mais cláusulas booleanas, cada cláusula com uma ocorrência digitada. Os tipos de ocorrência são:
      _must_    : O termo deve, obrigatoriamente, aparecer no documento.
      _filter_  : O termo deve aparecer nos documentos correspondentes.
      _should_  : O termo deve aparecer no documento.
      _must_not_: O termo não deve, obrigatoriamente, aparecer no documento.
      
 
  *_Boosting_*
  Retorna documentos que correspondem a uma consulta positiva enquanto reduz a pontuação de relevância dos documentos que correspondem a uma consulta negativa. Essa consulta permite rebaixar certos documentos sem excluí-los dos resultados da pesquisa.
      
  *_Fuzzy_*
  Retorna documentos que contém termos semelhantes ao termo de pesquisa medido por uma distância de edição. Uma distância de edição é o número de alterações de um caractere necessárias para transformar um termo em outro. Essas mudanças podem incluir:

- Mudando um caracter que muda a palavra (gato -> galo)
- Removendo caracteres (acreditar -> creditar)
- Inserindo caracteres (calor -> calorímetro)
- Transpondo caracteres adjacentes (papo -> popa)
     
   Para encontrar termos semelhantes, a consulta do tipo fuzzy cria um conjunto de todas as variações ou expansões possíveis do termo de pesquisa dentro de uma distância de edição especificada. A consulta retorna correspondências exatas para cada expansão.
  
  *_Express?es regulares_*
   Retorna documentos que contém termos que correspondem a uma expressão regular. Uma expressão regular é uma maneira de combinar padrões em dados usando caracteres de espaço reservado, chamados de operadores. Para obter uma lista de operadores suportados pela consulta regexp.

>> **3** Stopwords e Stoplists
   
   O processo de criação das palavras de busca é acompanhado de um longo trabalho envolvendo uma curadoria de jornalistas especializados. Foram selecionados voluntariamente sete jornalistas para compor a equipe de curadoria e avaliar os documentos coletados através dos mecanismos de busca e avaliar qualitativamente os resultados. 
   
   Para esta fase do projeto os curadores irão avaliar cerca de 776 termos de busca. Na primeira etapa serão gerados 488 termos acompanhados de excertos dos Diários Oficiais coletados, denominados de _highlights_. A partir dos resultados da primeira etapa será necessário mais duas avaliações de 144 termos para concluir o processo.
   
   A definição das stopwords e stoplists é crucial para a determinação do escopo do projeto, ou seja, o que será encontrado na platadorma Diário do Clima. 
   
>> **4** Avaliação de precisão

A avaliação de precisão é realizada concomitantemente com as criações de stopwords e stoplists, já que estas duas etapas são interdependentes. 

   Na avaliação feita pelos curadores, existem dois parâmetros que podem ser explorados, um deles diz respeito se o documento possui o escopo adequado (positivo) ou não (negativo) e o outro é com relação aos comentários dos curadores no documento, sendo este indicador opcional. Na distribuição dos termos, há ainda mais um parâmetro que também pode ser adicionado, que é a qualidade dos documentos baseados nas palavras coletadas via ElasticSearch, assim os primeiros documentos possuem uma qualidade teórica maior do que aqueles que vem por último para cada termo de busca.
   
   Todos os documentos são avaliados, portanto é possível tirar conclusões muito importantes para o desenvolvimento das buscas nos Diários Oficiais dos municípios. As avaliações serão divididas em análises quantitativa e qualitativa.

 * **Quantitativa**
 
 A análise quantitativa se baseará em duas principais relações: Índices positivos e negativos de busca, relação entre qualidade do documento ElasticSearch versus qualidade pela Curadoria.
 
 O primeiro inferirá sobre a distribuição das avaliaçõe negativas e positivas dos documentos, podendo então saber se os documentos coletados estão coerentes com o objetivo da plataforma. O segundo ajudará a melhorar a qualidade traçando uma relação entre os índices de qualidade pelo ElasticSearch e a quantidade de índices positivos ou negativos daquela busca.

  * **Qualitativa**
  
 A análise qualitativa será realizada para observar o conteúdo dos highlights e comentários realizados. Assim, será possível avaliar se os highlights selecionados são adequados ao escopo do documento que ele faz parte
   
>> **5** Refinamento

   Após a coleta dos documentos e definição dos termos de busca será feita uma nova rodada de coleta de documentos para refinar os processos de busca. Essa etapa é necessária para deixar a plataforma mais eficaz e amigável, bem como melhorar o processamento dos documentos. 
   
   Esse processo vai de encontro com o que foi elencado na seção de Política ambiental no Brasil, onde puderam ser explorados os principais marcos da política ambiental brasileira bem como a avaliação dos documentos pelos curadores.Dessa forma, a plataforma será um grande êxito para os jornalistas e comunicadores que acompanham nóticias sobre clima e meio ambiente no Brasil. 


## Um Diário Municipal

## Mecanismos de Busca

## Termos de Interesse

## Anotação e Controle de Qualidade




